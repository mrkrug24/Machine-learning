Важное:
Использование имеющегося датасета недостаточно, необходимо учитываеть получаемые данные и корректировать модель в процесе работы
По этой причине был использован следующий подход:
    - При инициализации объекта класса Solution происходит обучение на данных из dev-dataset-task2024-04.json
    - Далее при использовании метода predict происходит добавление новых данных в выборку и запускается цикл обучения, учитывающий только что полученные данные (ранее обработанные)
Таким образом модель адаптируется к новым данным

__init__
    - Стоп-слова - nltk.download('stopwords')
    - Лемматизации - Mystem()
    - Токенезация - TfidfVectorizer (использую значения по умолчанию, кроме стоп-слов, которые загрузил с помощью nltk)
    - Загрузка и обработка данных с помощью text_processing и токенезатора
    - Создание и обучение модели - KNeighborsRegressor (использую значения по умолчанию, кроме  metric='cosine' и n_neighbors=1, которые лучше подходят для задачи кластеризации, разбиения текста на группы)

text_processing
    - Не привожу к нижнему регистру, так как это сделает токенезатор по умолчанию
    - Оставляю только буквы и пробелы
    - Привожу все слова к начальной форме с помощью лемматизатора

predict
    - Обрабатывает полученный текст помощью text_processing и токенезатора
    - Вычисляет значение для полученных данных
    - Дообогащает x и y новыми данными
    - Запускает обучение модели на полученной выборке